{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nama : Ken Foster Morintoh\\\n",
    "NIM  : 672020175\\\n",
    "Kelas : Big Data Analysis\\\n",
    "Tugas : Logistic Regression (Tugas Akhir Semester)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deskripsi Tugas** : \n",
    "\n",
    "Buat Program Klasifikasi dengan Logistic Regression dengan SPARK\\\n",
    "Dataset= titanic.csv\\\n",
    "Split train:test -> 70:30\\\n",
    "Kolom features (X): Pclass, Sex, Age,  SibSp, Parch, Fare, Embarked, Gelar\\\n",
    "Kolom target (Y): Survived\n",
    "\n",
    "Program (boleh) dibuat dengan kaggle\\\n",
    "Kirim file.ipynb ke suryasatriya@uksw.edu\\\n",
    "Batas Waktu: 24 Juni 2024, 24.00 WIB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| NULL|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| NULL|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| NULL|       S|\n",
      "|          6|       0|     3|    Moran, Mr. James|  male|NULL|    0|    0|          330877| 8.4583| NULL|       Q|\n",
      "|          7|       0|     1|McCarthy, Mr. Tim...|  male|54.0|    0|    0|           17463|51.8625|  E46|       S|\n",
      "|          8|       0|     3|Palsson, Master. ...|  male| 2.0|    3|    1|          349909| 21.075| NULL|       S|\n",
      "|          9|       1|     3|Johnson, Mrs. Osc...|female|27.0|    0|    2|          347742|11.1333| NULL|       S|\n",
      "|         10|       1|     2|Nasser, Mrs. Nich...|female|14.0|    1|    0|          237736|30.0708| NULL|       C|\n",
      "|         11|       1|     3|Sandstrom, Miss. ...|female| 4.0|    1|    1|         PP 9549|   16.7|   G6|       S|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|female|58.0|    0|    0|          113783|  26.55| C103|       S|\n",
      "|         13|       0|     3|Saundercock, Mr. ...|  male|20.0|    0|    0|       A/5. 2151|   8.05| NULL|       S|\n",
      "|         14|       0|     3|Andersson, Mr. An...|  male|39.0|    1|    5|          347082| 31.275| NULL|       S|\n",
      "|         15|       0|     3|Vestrom, Miss. Hu...|female|14.0|    0|    0|          350406| 7.8542| NULL|       S|\n",
      "|         16|       1|     2|Hewlett, Mrs. (Ma...|female|55.0|    0|    0|          248706|   16.0| NULL|       S|\n",
      "|         17|       0|     3|Rice, Master. Eugene|  male| 2.0|    4|    1|          382652| 29.125| NULL|       Q|\n",
      "|         18|       1|     2|Williams, Mr. Cha...|  male|NULL|    0|    0|          244373|   13.0| NULL|       S|\n",
      "|         19|       0|     3|Vander Planke, Mr...|female|31.0|    1|    0|          345763|   18.0| NULL|       S|\n",
      "|         20|       1|     3|Masselmani, Mrs. ...|female|NULL|    0|    0|            2649|  7.225| NULL|       C|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= spark.read.csv(\"titanic.csv\", inferSchema=True, header=True)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Menambahkan feature Gelar dan mengisikan valuenya dari ekstrasi dari kolom name**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- menggunakan regex untuk mendapatkan nilai gelar dari kolom Name yang akan dimasukan pada kolom(feature) Gelar.\\\n",
    "- Reggex akan menemukan mengektrak kolom title dari kolom namA\\\n",
    "    regexp_extract adalah fungsi yang disediakan oleh PySpark untuk mengekstraksi substring yang cocok dari kolom berdasarkan pola ekspresi reguler. Ini mengembalikan nilai yang cocok dengan grup penangkap tertentu.\n",
    "   - Argumen pertama adalah kolom tempat ekspresi reguler akan diterapkan. Di sini, df[\"Name\"], yang merujuk ke kolom \"Name\" di DataFrame.\n",
    "   - Argumen kedua adalah pola ekspresi reguler sebagai string mentah (r\"...\"). Dalam hal ini, polanya adalah r\"\\b(\\w+)\\.\"\n",
    "- untuk membuat kolom baru cukup menggunakan withColumn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|PassengerId|Survived|Pclass|Name                                                   |Sex   |Age |SibSp|Parch|Ticket          |Fare   |Cabin|Embarked|Gelar |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "|1          |0       |3     |Braund, Mr. Owen Harris                                |male  |22.0|1    |0    |A/5 21171       |7.25   |NULL |S       |Mr    |\n",
      "|2          |1       |1     |Cumings, Mrs. John Bradley (Florence Briggs Thayer)    |female|38.0|1    |0    |PC 17599        |71.2833|C85  |C       |Mrs   |\n",
      "|3          |1       |3     |Heikkinen, Miss. Laina                                 |female|26.0|0    |0    |STON/O2. 3101282|7.925  |NULL |S       |Miss  |\n",
      "|4          |1       |1     |Futrelle, Mrs. Jacques Heath (Lily May Peel)           |female|35.0|1    |0    |113803          |53.1   |C123 |S       |Mrs   |\n",
      "|5          |0       |3     |Allen, Mr. William Henry                               |male  |35.0|0    |0    |373450          |8.05   |NULL |S       |Mr    |\n",
      "|6          |0       |3     |Moran, Mr. James                                       |male  |NULL|0    |0    |330877          |8.4583 |NULL |Q       |Mr    |\n",
      "|7          |0       |1     |McCarthy, Mr. Timothy J                                |male  |54.0|0    |0    |17463           |51.8625|E46  |S       |Mr    |\n",
      "|8          |0       |3     |Palsson, Master. Gosta Leonard                         |male  |2.0 |3    |1    |349909          |21.075 |NULL |S       |Master|\n",
      "|9          |1       |3     |Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)      |female|27.0|0    |2    |347742          |11.1333|NULL |S       |Mrs   |\n",
      "|10         |1       |2     |Nasser, Mrs. Nicholas (Adele Achem)                    |female|14.0|1    |0    |237736          |30.0708|NULL |C       |Mrs   |\n",
      "|11         |1       |3     |Sandstrom, Miss. Marguerite Rut                        |female|4.0 |1    |1    |PP 9549         |16.7   |G6   |S       |Miss  |\n",
      "|12         |1       |1     |Bonnell, Miss. Elizabeth                               |female|58.0|0    |0    |113783          |26.55  |C103 |S       |Miss  |\n",
      "|13         |0       |3     |Saundercock, Mr. William Henry                         |male  |20.0|0    |0    |A/5. 2151       |8.05   |NULL |S       |Mr    |\n",
      "|14         |0       |3     |Andersson, Mr. Anders Johan                            |male  |39.0|1    |5    |347082          |31.275 |NULL |S       |Mr    |\n",
      "|15         |0       |3     |Vestrom, Miss. Hulda Amanda Adolfina                   |female|14.0|0    |0    |350406          |7.8542 |NULL |S       |Miss  |\n",
      "|16         |1       |2     |Hewlett, Mrs. (Mary D Kingcome)                        |female|55.0|0    |0    |248706          |16.0   |NULL |S       |Mrs   |\n",
      "|17         |0       |3     |Rice, Master. Eugene                                   |male  |2.0 |4    |1    |382652          |29.125 |NULL |Q       |Master|\n",
      "|18         |1       |2     |Williams, Mr. Charles Eugene                           |male  |NULL|0    |0    |244373          |13.0   |NULL |S       |Mr    |\n",
      "|19         |0       |3     |Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)|female|31.0|1    |0    |345763          |18.0   |NULL |S       |Mrs   |\n",
      "|20         |1       |3     |Masselmani, Mrs. Fatima                                |female|NULL|0    |0    |2649            |7.225  |NULL |C       |Mrs   |\n",
      "+-----------+--------+------+-------------------------------------------------------+------+----+-----+-----+----------------+-------+-----+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#menambah Kolom gelar dan memasukan valuenya\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "df = df.withColumn(\"Gelar\", regexp_extract(df[\"Name\"], r\"\\b(\\w+)\\.\", 1))\n",
    "\n",
    "#Print dataset.\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berdasarkan data diatas, penambahan kolom dengan gelar berhasil ditambahkan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked',\n",
       " 'Gelar']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Gelar: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature selection berdasarkan instruksi : Kolom features (X): Pclass, Sex, Age,  SibSp, Parch, Fare, Embarked, Gelar**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked| Gelar|\n",
      "+--------+------+------+----+-----+-----+-------+--------+------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|    Mr|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|   Mrs|\n",
      "|       1|     3|female|26.0|    0|    0|  7.925|       S|  Miss|\n",
      "|       1|     1|female|35.0|    1|    0|   53.1|       S|   Mrs|\n",
      "|       0|     3|  male|35.0|    0|    0|   8.05|       S|    Mr|\n",
      "|       0|     1|  male|54.0|    0|    0|51.8625|       S|    Mr|\n",
      "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|Master|\n",
      "|       1|     3|female|27.0|    0|    2|11.1333|       S|   Mrs|\n",
      "|       1|     2|female|14.0|    1|    0|30.0708|       C|   Mrs|\n",
      "|       1|     3|female| 4.0|    1|    1|   16.7|       S|  Miss|\n",
      "|       1|     1|female|58.0|    0|    0|  26.55|       S|  Miss|\n",
      "|       0|     3|  male|20.0|    0|    0|   8.05|       S|    Mr|\n",
      "|       0|     3|  male|39.0|    1|    5| 31.275|       S|    Mr|\n",
      "|       0|     3|female|14.0|    0|    0| 7.8542|       S|  Miss|\n",
      "|       1|     2|female|55.0|    0|    0|   16.0|       S|   Mrs|\n",
      "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|Master|\n",
      "|       0|     3|female|31.0|    1|    0|   18.0|       S|   Mrs|\n",
      "|       0|     2|  male|35.0|    0|    0|   26.0|       S|    Mr|\n",
      "|       1|     2|  male|34.0|    0|    0|   13.0|       S|    Mr|\n",
      "|       1|     3|female|15.0|    0|    0| 8.0292|       Q|  Miss|\n",
      "+--------+------+------+----+-----+-----+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rm_columns = df.select(['Survived','Pclass', \n",
    "                       'Sex','Age','SibSp', \n",
    "                       'Parch','Fare','Embarked', 'Gelar']) \n",
    "  \n",
    "# menghapus data null\n",
    "result = rm_columns.na.drop() \n",
    "  \n",
    "  \n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat terlihat dataframe diatas masih ada tiga data yang bertipe non numerik. Untuk itu perlu penkonversian sehingga data menjadi numerik semua agar dapat dilakukan logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Mengubah Kolom Sex menjadi numerik**\n",
    "\n",
    "- saya menggunakan library pyspark.sql library untuk menemukan dan mengubah kata male menjadi 1 dan 0 untuk lainnya pada kolom Sex.\n",
    "- menyimpannya dalam result_num_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "result_num_sex = result.withColumn('Sex', when(col(\"Sex\") == \"male\", 1).otherwise(0))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+----+-----+-----+-------+--------+------+\n",
      "|Survived|Pclass|Sex| Age|SibSp|Parch|   Fare|Embarked| Gelar|\n",
      "+--------+------+---+----+-----+-----+-------+--------+------+\n",
      "|       0|     3|  1|22.0|    1|    0|   7.25|       S|    Mr|\n",
      "|       1|     1|  0|38.0|    1|    0|71.2833|       C|   Mrs|\n",
      "|       1|     3|  0|26.0|    0|    0|  7.925|       S|  Miss|\n",
      "|       1|     1|  0|35.0|    1|    0|   53.1|       S|   Mrs|\n",
      "|       0|     3|  1|35.0|    0|    0|   8.05|       S|    Mr|\n",
      "|       0|     1|  1|54.0|    0|    0|51.8625|       S|    Mr|\n",
      "|       0|     3|  1| 2.0|    3|    1| 21.075|       S|Master|\n",
      "|       1|     3|  0|27.0|    0|    2|11.1333|       S|   Mrs|\n",
      "|       1|     2|  0|14.0|    1|    0|30.0708|       C|   Mrs|\n",
      "|       1|     3|  0| 4.0|    1|    1|   16.7|       S|  Miss|\n",
      "|       1|     1|  0|58.0|    0|    0|  26.55|       S|  Miss|\n",
      "|       0|     3|  1|20.0|    0|    0|   8.05|       S|    Mr|\n",
      "|       0|     3|  1|39.0|    1|    5| 31.275|       S|    Mr|\n",
      "|       0|     3|  0|14.0|    0|    0| 7.8542|       S|  Miss|\n",
      "|       1|     2|  0|55.0|    0|    0|   16.0|       S|   Mrs|\n",
      "|       0|     3|  1| 2.0|    4|    1| 29.125|       Q|Master|\n",
      "|       0|     3|  0|31.0|    1|    0|   18.0|       S|   Mrs|\n",
      "|       0|     2|  1|35.0|    0|    0|   26.0|       S|    Mr|\n",
      "|       1|     2|  1|34.0|    0|    0|   13.0|       S|    Mr|\n",
      "|       1|     3|  0|15.0|    0|    0| 8.0292|       Q|  Miss|\n",
      "+--------+------+---+----+-----+-----+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_num_sex.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Mengubah kolom Embarked menjadi numerik**\n",
    "- pertama-tama, untuk memastikan jumlah kategoti yang ada pada embarked, saya melakukan cek nilai unik pada kolom embarked\n",
    "- setelah didapatkan, saya membuatkan mapping untuk setiap kategori pada embarked.\n",
    "- mapping tersebut yang nantinya digunakan untuk mengubah nilai kategori embarked menjadi numerik\n",
    "- Kemudian terakhir menerapakan metode when-otherwise unutk mengubah nilai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah kategori unik dalam feature 'Embarked': 3\n"
     ]
    }
   ],
   "source": [
    "#memilih kolom\n",
    "distinct_values = result_num_sex.select('Embarked').distinct()\n",
    "\n",
    "# hitung kategori unik \n",
    "unique_count = distinct_values.count()\n",
    "print(f\"Jumlah kategori unik dalam feature 'Embarked': {unique_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# menentukan mapping setiap value pada embarked\n",
    "category_mapping = {\"Q\": 1, \"C\": 2, \"S\": 3}\n",
    "\n",
    "# melakukan transpormasi menggunakan when otherwise method\n",
    "result_num_sex_embarked = result_num_sex.withColumn(\"Embarked\", \n",
    "                           when(col(\"Embarked\") == \"Q\", category_mapping[\"Q\"])\n",
    "                           .when(col(\"Embarked\") == \"C\", category_mapping[\"C\"])\n",
    "                           .when(col(\"Embarked\") == \"S\", category_mapping[\"S\"])\n",
    "                           .otherwise(0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+----+-----+-----+-------+--------+------+\n",
      "|Survived|Pclass|Sex| Age|SibSp|Parch|   Fare|Embarked| Gelar|\n",
      "+--------+------+---+----+-----+-----+-------+--------+------+\n",
      "|       0|     3|  1|22.0|    1|    0|   7.25|       3|    Mr|\n",
      "|       1|     1|  0|38.0|    1|    0|71.2833|       2|   Mrs|\n",
      "|       1|     3|  0|26.0|    0|    0|  7.925|       3|  Miss|\n",
      "|       1|     1|  0|35.0|    1|    0|   53.1|       3|   Mrs|\n",
      "|       0|     3|  1|35.0|    0|    0|   8.05|       3|    Mr|\n",
      "|       0|     1|  1|54.0|    0|    0|51.8625|       3|    Mr|\n",
      "|       0|     3|  1| 2.0|    3|    1| 21.075|       3|Master|\n",
      "|       1|     3|  0|27.0|    0|    2|11.1333|       3|   Mrs|\n",
      "|       1|     2|  0|14.0|    1|    0|30.0708|       2|   Mrs|\n",
      "|       1|     3|  0| 4.0|    1|    1|   16.7|       3|  Miss|\n",
      "|       1|     1|  0|58.0|    0|    0|  26.55|       3|  Miss|\n",
      "|       0|     3|  1|20.0|    0|    0|   8.05|       3|    Mr|\n",
      "|       0|     3|  1|39.0|    1|    5| 31.275|       3|    Mr|\n",
      "|       0|     3|  0|14.0|    0|    0| 7.8542|       3|  Miss|\n",
      "|       1|     2|  0|55.0|    0|    0|   16.0|       3|   Mrs|\n",
      "|       0|     3|  1| 2.0|    4|    1| 29.125|       1|Master|\n",
      "|       0|     3|  0|31.0|    1|    0|   18.0|       3|   Mrs|\n",
      "|       0|     2|  1|35.0|    0|    0|   26.0|       3|    Mr|\n",
      "|       1|     2|  1|34.0|    0|    0|   13.0|       3|    Mr|\n",
      "|       1|     3|  0|15.0|    0|    0| 8.0292|       1|  Miss|\n",
      "+--------+------+---+----+-----+-----+-------+--------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result_num_sex_embarked.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Mengubah kolom Gelar menjadi numerik**\n",
    "- Melihat kategori yang ada \n",
    "- Mapping setiap kategori ke numerik\n",
    "- Lalu menggunakan metode when-otherwise untuk melakukan konversi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|   Gelar|count|\n",
      "+--------+-----+\n",
      "|     Don|    1|\n",
      "|    Miss|  145|\n",
      "|Countess|    1|\n",
      "|     Col|    2|\n",
      "|     Rev|    6|\n",
      "|    Lady|    1|\n",
      "|  Master|   36|\n",
      "|     Mme|    1|\n",
      "|    Capt|    1|\n",
      "|      Mr|  398|\n",
      "|      Dr|    6|\n",
      "|     Mrs|  107|\n",
      "|     Sir|    1|\n",
      "|Jonkheer|    1|\n",
      "|    Mlle|    2|\n",
      "|   Major|    2|\n",
      "|      Ms|    1|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import count\n",
    "category_counts = result_num_sex.groupBy(\"Gelar\").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "category_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mengubah Nilai Kategorikal pada kolom Gelar\n",
    "- setiap kategori yang ditemukan akan digantikan dengan angka pada mapping yang kita buat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+----+-----+-----+-------+--------+-----+\n",
      "|Survived|Pclass|Sex| Age|SibSp|Parch|   Fare|Embarked|Gelar|\n",
      "+--------+------+---+----+-----+-----+-------+--------+-----+\n",
      "|       0|     3|  1|22.0|    1|    0|   7.25|       3|   13|\n",
      "|       1|     1|  0|38.0|    1|    0|71.2833|       2|   14|\n",
      "|       1|     3|  0|26.0|    0|    0|  7.925|       3|   10|\n",
      "|       1|     1|  0|35.0|    1|    0|   53.1|       3|   14|\n",
      "|       0|     3|  1|35.0|    0|    0|   8.05|       3|   13|\n",
      "|       0|     1|  1|54.0|    0|    0|51.8625|       3|   13|\n",
      "|       0|     3|  1| 2.0|    3|    1| 21.075|       3|    9|\n",
      "|       1|     3|  0|27.0|    0|    2|11.1333|       3|   14|\n",
      "|       1|     2|  0|14.0|    1|    0|30.0708|       2|   14|\n",
      "|       1|     3|  0| 4.0|    1|    1|   16.7|       3|   10|\n",
      "|       1|     1|  0|58.0|    0|    0|  26.55|       3|   10|\n",
      "|       0|     3|  1|20.0|    0|    0|   8.05|       3|   13|\n",
      "|       0|     3|  1|39.0|    1|    5| 31.275|       3|   13|\n",
      "|       0|     3|  0|14.0|    0|    0| 7.8542|       3|   10|\n",
      "|       1|     2|  0|55.0|    0|    0|   16.0|       3|   14|\n",
      "|       0|     3|  1| 2.0|    4|    1| 29.125|       1|    9|\n",
      "|       0|     3|  0|31.0|    1|    0|   18.0|       3|   14|\n",
      "|       0|     2|  1|35.0|    0|    0|   26.0|       3|   13|\n",
      "|       1|     2|  1|34.0|    0|    0|   13.0|       3|   13|\n",
      "|       1|     3|  0|15.0|    0|    0| 8.0292|       1|   10|\n",
      "+--------+------+---+----+-----+-----+-------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mengubaha Miss Mr \n",
    "category_mapping1 = {\n",
    "    'Capt': 1, 'Col': 2, 'Countess': 3, 'Don': 4, \n",
    "    'Dr': 5, 'Jonkheer': 6, 'Lady': 7, 'Major': 8, \n",
    "    'Master': 9, 'Miss': 10, 'Mlle': 11, 'Mme': 12, \n",
    "    'Mr': 13, 'Mrs': 14, 'Ms': 15, 'Rev': 16, 'Sir': 17\n",
    "}\n",
    "\n",
    "\n",
    "# Apply transformation using 'when' and 'otherwise'\n",
    "my_final_dataset = result_num_sex_embarked.withColumn(\"Gelar\", when(col(\"Gelar\") == \"Capt\", category_mapping1[\"Capt\"])\n",
    "                           .when(col(\"Gelar\") == \"Col\", category_mapping1[\"Col\"])\n",
    "                           .when(col(\"Gelar\") == \"Countess\", category_mapping1[\"Countess\"])\n",
    "                           .when(col(\"Gelar\") == \"Don\", category_mapping1[\"Don\"])\n",
    "                           .when(col(\"Gelar\") == \"Dr\", category_mapping1[\"Dr\"])\n",
    "                           .when(col(\"Gelar\") == \"Jonkheer\", category_mapping1[\"Jonkheer\"])\n",
    "                           .when(col(\"Gelar\") == \"Lady\", category_mapping1[\"Lady\"])\n",
    "                           .when(col(\"Gelar\") == \"Major\", category_mapping1[\"Major\"])\n",
    "                           .when(col(\"Gelar\") == \"Master\", category_mapping1[\"Master\"])\n",
    "                           .when(col(\"Gelar\") == \"Miss\", category_mapping1[\"Miss\"])\n",
    "                           .when(col(\"Gelar\") == \"Mlle\", category_mapping1[\"Mlle\"])\n",
    "                           .when(col(\"Gelar\") == \"Mme\", category_mapping1[\"Mme\"])\n",
    "                           .when(col(\"Gelar\") == \"Mr\", category_mapping1[\"Mr\"])\n",
    "                           .when(col(\"Gelar\") == \"Mrs\", category_mapping1[\"Mrs\"])\n",
    "                           .when(col(\"Gelar\") == \"Ms\", category_mapping1[\"Ms\"])\n",
    "                           .when(col(\"Gelar\") == \"Rev\", category_mapping1[\"Rev\"])\n",
    "                           .when(col(\"Gelar\") == \"Sir\", category_mapping1[\"Sir\"])\n",
    "                         )\n",
    "my_final_dataset.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Melakukan vector assembler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.feature import VectorAssembler, OneHotEncoder \n",
    "\n",
    "# Encode kolom Sex \n",
    "sexEncode = OneHotEncoder(inputCol='Sex', \n",
    "                               outputCol='SexVec') \n",
    "# Encode kolom embarked\n",
    "embarkEncode = OneHotEncoder(inputCol='Embarked', \n",
    "                               outputCol='EmbarkVec') \n",
    "# encode kolom Gelar \n",
    "gelarEncode = OneHotEncoder(inputCol='Gelar',\n",
    "                            outputCol='GelarVec')\n",
    "    \n",
    "# Melakukan Vektorisasi data menjadi kolom baru \"feature\"\n",
    "assembler = VectorAssembler(inputCols=['Pclass', \n",
    "                                       'SexVec','Age', \n",
    "                                       'SibSp','Parch', \n",
    "                                       'Fare','EmbarkVec', 'GelarVec'], \n",
    "                                    outputCol='features')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pipelining**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Menginport pipeline dan model yang saya gunakan \n",
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.classification import LogisticRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target Kolom Y (\"Survived\")**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features', \n",
    "                             labelCol='Survived') \n",
    "  \n",
    "# Membuat papeline\n",
    "pipelineku = Pipeline(stages=[sexEncode, embarkEncode, gelarEncode,\n",
    "                            assembler, log_reg]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split train:test 70:30** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+----+-----+-----+-------+--------+-----+---------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Sex| Age|SibSp|Parch|   Fare|Embarked|Gelar|   SexVec|    EmbarkVec|       GelarVec|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+---+----+-----+-----+-------+--------+-----+---------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|  1|18.0|    1|    0|  108.9|       2|   13|(1,[],[])|(3,[2],[1.0])|(17,[13],[1.0])|(26,[0,2,3,5,8,22...|[-0.3087954431551...|[0.42340878472684...|       1.0|\n",
      "|       0|     1|  1|21.0|    0|    1|77.2875|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,4,5,22],...|[-0.2115477733081...|[0.44730941304637...|       1.0|\n",
      "|       0|     1|  1|27.0|    0|    2|  211.5|       2|   13|(1,[],[])|(3,[2],[1.0])|(17,[13],[1.0])|(26,[0,2,4,5,8,22...|[-0.1986319160931...|[0.45050464916244...|       1.0|\n",
      "|       0|     1|  1|29.0|    1|    0|   66.6|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,3,5,22],...|[0.33247994270703...|[0.58236266247371...|       0.0|\n",
      "|       0|     1|  1|30.0|    0|    0|  27.75|       2|   13|(1,[],[])|(3,[2],[1.0])|(17,[13],[1.0])|(26,[0,2,5,8,22],...|[-0.3694066470022...|[0.40868440434709...|       1.0|\n",
      "|       0|     1|  1|31.0|    0|    0|50.4958|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,5,22],[1...|[-0.1476750319849...|[0.46314818943740...|       1.0|\n",
      "|       0|     1|  1|31.0|    1|    0|   52.0|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,3,5,22],...|[0.41912906325688...|[0.60327482357980...|       0.0|\n",
      "|       0|     1|  1|33.0|    0|    0|    5.0|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,5,22],[1...|[-0.0078050899632...|[0.49804873741499...|       1.0|\n",
      "|       0|     1|  1|37.0|    0|    1|   29.7|       2|   13|(1,[],[])|(3,[2],[1.0])|(17,[13],[1.0])|(26,[0,2,4,5,8,22...|[0.13225669991044...|[0.53301606304227...|       0.0|\n",
      "|       0|     1|  1|37.0|    1|    0|   53.1|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,3,5,22],...|[0.60173209706630...|[0.64605248268675...|       0.0|\n",
      "|       0|     1|  1|38.0|    0|    0|    0.0|       3|    6|(1,[],[])|    (3,[],[])| (17,[6],[1.0])|(26,[0,2,15],[1.0...|[-424.61973062438...|[3.89039844153366...|       1.0|\n",
      "|       0|     1|  1|40.0|    0|    0|    0.0|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,22],[1.0...|[0.21605539513649...|[0.55380471140813...|       0.0|\n",
      "|       0|     1|  1|44.0|    2|    0|   90.0|       1|    5|(1,[],[])|(3,[1],[1.0])| (17,[5],[1.0])|(26,[0,2,3,5,7,14...|[1.02860893272128...|[0.73664611956056...|       0.0|\n",
      "|       0|     1|  1|45.0|    0|    0|  26.55|       3|    8|(1,[],[])|    (3,[],[])| (17,[8],[1.0])|(26,[0,2,5,17],[1...|[-3215.1666664007...|           [0.0,1.0]|       1.0|\n",
      "|       0|     1|  1|45.0|    1|    0| 83.475|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,3,5,22],...|[0.79540557917636...|[0.68899083314353...|       0.0|\n",
      "|       0|     1|  1|50.0|    1|    0|106.425|       2|   13|(1,[],[])|(3,[2],[1.0])|(17,[13],[1.0])|(26,[0,2,3,5,8,22...|[0.67945668225587...|[0.66361742372741...|       0.0|\n",
      "|       0|     1|  1|52.0|    1|    1|  79.65|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,3,4,5,22...|[1.30701688807744...|[0.78701354517075...|       0.0|\n",
      "|       0|     1|  1|58.0|    0|    0|   29.7|       2|   13|(1,[],[])|(3,[2],[1.0])|(17,[13],[1.0])|(26,[0,2,5,8,22],...|[0.48822442488682...|[0.61968806311074...|       0.0|\n",
      "|       0|     1|  1|61.0|    0|    0|32.3208|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,5,22],[1...|[0.80612247473726...|[0.69128261224880...|       0.0|\n",
      "|       0|     1|  1|62.0|    0|    0|  26.55|       3|   13|(1,[],[])|    (3,[],[])|(17,[13],[1.0])|(26,[0,2,5,22],[1...|[0.84681284912949...|[0.69989813775701...|       0.0|\n",
      "+--------+------+---+----+-----+-----+-------+--------+-----+---------+-------------+---------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# split data 70:30\n",
    "train_data, test_data = my_final_dataset.randomSplit([0.7, .3]) \n",
    "  \n",
    "# fiting model\n",
    "fit_model = pipelineku.fit(train_data) \n",
    "  \n",
    "# menyimpan hasil fitting di \"result\"\n",
    "results = fit_model.transform(test_data) \n",
    "  \n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluasi Akurasi Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.805757874015748"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator \n",
    "my_res = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='Survived') \n",
    "# Evaluasi prediksi\n",
    "ROC_AUC = my_res.evaluate(results)\n",
    "ROC_AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modelnya cukup baik dengan akurasi 78-80%**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tunning hyper Parameter menggunakan String indexter untuk konversi ke numerik**\n",
    "- disini pengubahan nilai numerik dilakukan oleh StringIndexter tanpa bantuan kita untuk mengubah data string ke numerik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder \n",
    "  \n",
    "# convert kolom sex\n",
    "sexIdx = StringIndexer(inputCol='Sex', \n",
    "                               outputCol='SexIndex') \n",
    "sexEncode = OneHotEncoder(inputCol='SexIndex', \n",
    "                               outputCol='SexVec') \n",
    "  \n",
    "# conver kolom embark\n",
    "embarkIdx = StringIndexer(inputCol='Embarked', \n",
    "                               outputCol='EmbarkIndex') \n",
    "embarkEncode = OneHotEncoder(inputCol='EmbarkIndex', \n",
    "                               outputCol='EmbarkVec') \n",
    "\n",
    "#konver kolom gelar\n",
    "gelarIdx = StringIndexer(inputCol='Gelar', \n",
    "                               outputCol='GelarIndex') \n",
    "gelarEncode = OneHotEncoder(inputCol='GelarIndex', \n",
    "                               outputCol='GelarVec') \n",
    "\n",
    "\n",
    "# Melakukan vektorisasi data kedalam kolom baru \"features\"\n",
    "assembler2 = VectorAssembler(inputCols=['Pclass','SexVec','Age','SibSp','Parch', 'Fare','EmbarkVec', 'GelarVec'], outputCol='features') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline \n",
    "from pyspark.ml.classification import LogisticRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(featuresCol='features', labelCol='Survived') \n",
    "  \n",
    "# membuat pipelin\n",
    "pipeline= Pipeline(stages=[sexIdx, embarkIdx, gelarIdx, sexEncode, embarkEncode, gelarEncode, assembler2, log_reg]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#membagi data 70:30 persen \n",
    "train_data, test_data = my_final_dataset.randomSplit([0.7, .3]) \n",
    "  \n",
    "# fiting mmodel kdealam data train\n",
    "fit_model = pipeline.fit(train_data) \n",
    "  \n",
    "# menyimpan hasil fit ke \"Hasil\"\n",
    "Hasil = fit_model.transform(test_data) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+---+----+-----+-----+-------+--------+-----+--------+-----------+----------+-------------+-------------+--------------+--------------------+--------------------+--------------------+----------+\n",
      "|Survived|Pclass|Sex| Age|SibSp|Parch|   Fare|Embarked|Gelar|SexIndex|EmbarkIndex|GelarIndex|       SexVec|    EmbarkVec|      GelarVec|            features|       rawPrediction|         probability|prediction|\n",
      "+--------+------+---+----+-----+-----+-------+--------+-----+--------+-----------+----------+-------------+-------------+--------------+--------------------+--------------------+--------------------+----------+\n",
      "|       0|     1|  0| 2.0|    1|    2| 151.55|       3|   10|     1.0|        0.0|       1.0|    (1,[],[])|(2,[0],[1.0])|(16,[1],[1.0])|(24,[0,2,3,4,5,6,...|[-3.0224584861764...|[0.04642152433586...|       1.0|\n",
      "|       0|     1|  1|27.0|    0|    2|  211.5|       2|   13|     0.0|        1.0|       0.0|(1,[0],[1.0])|(2,[1],[1.0])|(16,[0],[1.0])|(24,[0,1,2,4,5,7,...|[-0.1335886812376...|[0.46665240819463...|       1.0|\n",
      "|       0|     1|  1|29.0|    0|    0|   30.0|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[-0.0846515378387...|[0.47884974405352...|       1.0|\n",
      "|       0|     1|  1|31.0|    0|    0|50.4958|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[-0.0616605392203...|[0.48458974739561...|       1.0|\n",
      "|       0|     1|  1|36.0|    0|    0| 40.125|       2|   13|     0.0|        1.0|       0.0|(1,[0],[1.0])|(2,[1],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,7,8]...|[-0.1267620458958...|[0.46835185567158...|       1.0|\n",
      "|       0|     1|  1|40.0|    0|    0|    0.0|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,6,8],[...|[0.42003565400502...|[0.60349178152350...|       0.0|\n",
      "|       0|     1|  1|44.0|    2|    0|   90.0|       1|    5|     0.0|        2.0|       5.0|(1,[0],[1.0])|    (2,[],[])|(16,[5],[1.0])|(24,[0,1,2,3,5,13...|[0.89599908162979...|[0.71012661926119...|       0.0|\n",
      "|       0|     1|  1|45.0|    0|    0|   35.5|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[0.51922397402488...|[0.62696628758822...|       0.0|\n",
      "|       0|     1|  1|46.0|    1|    0| 61.175|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,3,5,6,...|[1.05819053104047...|[0.74234460160994...|       0.0|\n",
      "|       0|     1|  1|47.0|    0|    0|   52.0|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[0.55280413420729...|[0.63478592653994...|       0.0|\n",
      "|       0|     1|  1|50.0|    1|    0|106.425|       2|   13|     0.0|        1.0|       0.0|(1,[0],[1.0])|(2,[1],[1.0])|(16,[0],[1.0])|(24,[0,1,2,3,5,7,...|[0.80703666377332...|[0.69147767608656...|       0.0|\n",
      "|       0|     1|  1|55.0|    0|    0|   30.5|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[0.91900615960399...|[0.71483956059921...|       0.0|\n",
      "|       0|     1|  1|58.0|    0|    2|113.275|       2|   13|     0.0|        1.0|       0.0|(1,[0],[1.0])|(2,[1],[1.0])|(16,[0],[1.0])|(24,[0,1,2,4,5,7,...|[1.32496338030424...|[0.79000629841716...|       0.0|\n",
      "|       0|     1|  1|62.0|    0|    0|  26.55|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[1.20004622234480...|[0.76853300609513...|       0.0|\n",
      "|       0|     1|  1|64.0|    1|    4|  263.0|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,3,4,5,...|[2.80951334798677...|[0.94318774775144...|       0.0|\n",
      "|       0|     1|  1|65.0|    0|    0|  26.55|       3|   13|     0.0|        0.0|       0.0|(1,[0],[1.0])|(2,[0],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,6,8]...|[1.31600576856709...|[0.78851640291886...|       0.0|\n",
      "|       0|     1|  1|71.0|    0|    0|34.6542|       2|   13|     0.0|        1.0|       0.0|(1,[0],[1.0])|(2,[1],[1.0])|(16,[0],[1.0])|(24,[0,1,2,5,7,8]...|[1.24059734588890...|[0.77566797385147...|       0.0|\n",
      "|       0|     2|  0|26.0|    1|    1|   26.0|       3|   14|     1.0|        0.0|       2.0|    (1,[],[])|(2,[0],[1.0])|(16,[2],[1.0])|(24,[0,2,3,4,5,6,...|[-2.0676423655363...|[0.11228182013770...|       1.0|\n",
      "|       0|     2|  0|27.0|    1|    0|   21.0|       3|   14|     1.0|        0.0|       2.0|    (1,[],[])|(2,[0],[1.0])|(16,[2],[1.0])|(24,[0,2,3,5,6,10...|[-2.4133429476998...|[0.08216087250771...|       1.0|\n",
      "|       0|     2|  0|38.0|    0|    0|   13.0|       3|   10|     1.0|        0.0|       1.0|    (1,[],[])|(2,[0],[1.0])|(16,[1],[1.0])|(24,[0,2,5,6,9],[...|[-1.3053675710186...|[0.21326304954419...|       1.0|\n",
      "+--------+------+---+----+-----+-----+-------+--------+-----+--------+-----------+----------+-------------+-------------+--------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Hasil.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluasi model dimana saya menggunakan string indexter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8425693864290354"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "res = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='Survived') \n",
    "\n",
    "# Evaluating the AUC on results \n",
    "ROC_AUC2 = res.evaluate(Hasil) \n",
    "\n",
    "ROC_AUC2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disini saya mendapatkan akurasi yang lebih baik. Dapat dikatakan tunning berhasil"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
